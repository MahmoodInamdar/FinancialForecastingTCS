{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Analysis Experiment with Claude 4 Sonnet\n",
    "\n",
    "This notebook experiments with financial metrics extraction and analysis using Claude 4 Sonnet API.\n",
    "\n",
    "## Objectives:\n",
    "1. Load and analyze TCS financial data from extracted tables\n",
    "2. Use Claude 4 Sonnet for advanced financial analysis\n",
    "3. Generate financial insights and trend analysis\n",
    "4. Calculate key financial ratios and metrics\n",
    "5. Create structured financial forecasting inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "from typing import Dict, List, Any, Optional\n",
    "import re\n",
    "\n",
    "# API and analysis libraries\n",
    "import anthropic\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"üì¶ Libraries imported successfully\")\n",
    "print(f\"üìä Pandas version: {pd.__version__}\")\n",
    "print(f\"üé® Matplotlib/Seaborn ready for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = \"data\"\n",
    "PDFS_DIR = os.path.join(DATA_DIR, \"pdfs\")\n",
    "EXCEL_DIR = os.path.join(DATA_DIR, \"excel_data\")\n",
    "EXTRACTION_OUTPUT_DIR = \"outputs/table_extraction\"\n",
    "ANALYSIS_OUTPUT_DIR = \"outputs/financial_analysis\"\n",
    "\n",
    "# API Configuration\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY', 'your-api-key-here')\n",
    "CLAUDE_MODEL = \"claude-3-5-sonnet-20241022\"  # Latest Claude model\n",
    "\n",
    "# Analysis parameters\n",
    "QUARTERS_TO_ANALYZE = 3  \n",
    "KEY_METRICS = [\n",
    "    'revenue', 'net_profit', 'operating_margin', 'profit_margin',\n",
    "    'eps', 'roa', 'roe', 'debt_to_equity', 'current_ratio',\n",
    "    'gross_margin', 'ebitda', 'roic', 'asset_turnover',\n",
    "    'quick_ratio', 'interest_coverage', 'debt_to_ebitda',\n",
    "    'revenue_growth', 'eps_growth', 'pe_ratio', 'price_to_book',\n",
    "    'price_to_sales', 'ev_ebitda', 'free_cash_flow',\n",
    "    'dividend_yield', 'beta'\n",
    "]\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(ANALYSIS_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Data directories configured\")\n",
    "print(f\"ü§ñ Claude model: {CLAUDE_MODEL}\")\n",
    "print(f\"üíæ Analysis output: {ANALYSIS_OUTPUT_DIR}\")\n",
    "print(f\"üîë API key configured: {'‚úÖ' if ANTHROPIC_API_KEY != 'your-api-key-here' else '‚ùå Need to set ANTHROPIC_API_KEY'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Claude client\n",
    "def initialize_claude_client():\n",
    "    \"\"\"\n",
    "    Initialize Claude API client\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if ANTHROPIC_API_KEY == 'your-api-key-here':\n",
    "            print(\"‚ö†Ô∏è Claude API key not configured. Using mock responses.\")\n",
    "            return None\n",
    "        \n",
    "        client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "        \n",
    "        # Test the connection\n",
    "        test_response = client.messages.create(\n",
    "            model=CLAUDE_MODEL,\n",
    "            max_tokens=100,\n",
    "            messages=[{\n",
    "                \"role\": \"user\", \n",
    "                \"content\": \"Hello, confirm you can analyze financial data.\"\n",
    "            }]\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Claude API client initialized successfully\")\n",
    "        return client\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize Claude client: {e}\")\n",
    "        print(\"‚ùå Claude API unavailable. Using fallback analysis.\")\n",
    "        return None\n",
    "\n",
    "# Initialize Claude\n",
    "claude_client = initialize_claude_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare financial data\n",
    "def load_financial_data() -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load financial data from Excel files and extracted table data\n",
    "    \"\"\"\n",
    "    data_sources = {}\n",
    "    \n",
    "    # Load Excel data\n",
    "    excel_files = [f for f in os.listdir(EXCEL_DIR) if f.endswith(('.xlsx', '.xls'))]\n",
    "    \n",
    "    for excel_file in excel_files:\n",
    "        try:\n",
    "            excel_path = os.path.join(EXCEL_DIR, excel_file)\n",
    "            excel_data = pd.read_excel(excel_path, sheet_name=None)\n",
    "            \n",
    "            for sheet_name, df in excel_data.items():\n",
    "                key = f\"{excel_file.split('.')[0]}_{sheet_name}\"\n",
    "                data_sources[key] = df\n",
    "                print(f\"üìä Loaded: {key} ({df.shape[0]}x{df.shape[1]})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading {excel_file}: {e}\")\n",
    "    \n",
    "    # Load extracted table data if available\n",
    "    if os.path.exists(EXTRACTION_OUTPUT_DIR):\n",
    "        extraction_files = [f for f in os.listdir(EXTRACTION_OUTPUT_DIR) if f.endswith('.csv')]\n",
    "        \n",
    "        for csv_file in extraction_files:\n",
    "            try:\n",
    "                csv_path = os.path.join(EXTRACTION_OUTPUT_DIR, csv_file)\n",
    "                df = pd.read_csv(csv_path)\n",
    "                key = f\"extracted_{csv_file.split('.')[0]}\"\n",
    "                data_sources[key] = df\n",
    "                print(f\"üìã Loaded: {key} ({df.shape[0]}x{df.shape[1]})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error loading {csv_file}: {e}\")\n",
    "    \n",
    "    return data_sources\n",
    "\n",
    "def create_sample_financial_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create sample TCS financial data for demonstration\n",
    "    \"\"\"\n",
    "    quarters = ['Q1 FY24', 'Q2 FY24', 'Q3 FY24', 'Q4 FY24', 'Q1 FY25', 'Q2 FY25', 'Q3 FY25', 'Q4 FY25']\n",
    "    \n",
    "    # Sample TCS-like financial data (in Crores INR)\n",
    "    sample_data = {\n",
    "        'Quarter': quarters,\n",
    "        'Revenue': [59381, 60583, 61327, 62191, 64106, 65219, 66528, 67819],\n",
    "        'Net_Profit': [11074, 11392, 11735, 12040, 12434, 12809, 13154, 13498],\n",
    "        'Operating_Margin': [24.1, 24.3, 24.7, 24.9, 25.1, 25.3, 25.0, 24.8],\n",
    "        'Profit_Margin': [18.6, 18.8, 19.1, 19.4, 19.4, 19.6, 19.8, 19.9],\n",
    "        'EPS': [30.2, 31.0, 32.0, 32.8, 33.9, 34.9, 35.8, 36.8],\n",
    "        'ROE': [29.8, 30.1, 30.5, 30.8, 31.2, 31.5, 31.8, 32.1],\n",
    "        'Employee_Count': [614795, 616171, 618348, 623304, 627644, 632818, 635456, 638015]\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(sample_data)\n",
    "\n",
    "# Load financial data\n",
    "print(\"üîÑ Loading financial data...\")\n",
    "financial_data_sources = load_financial_data()\n",
    "\n",
    "if not financial_data_sources:\n",
    "    print(\"üìä No data sources found. Creating sample data for demonstration.\")\n",
    "    sample_df = create_sample_financial_data()\n",
    "    financial_data_sources['sample_tcs_data'] = sample_df\n",
    "    print(\"‚úÖ Sample TCS financial data created\")\n",
    "\n",
    "print(f\"\\nüìà Available data sources: {list(financial_data_sources.keys())}\")\n",
    "\n",
    "# Show sample of first dataset\n",
    "if financial_data_sources:\n",
    "    first_key = list(financial_data_sources.keys())[0]\n",
    "    sample_data = financial_data_sources[first_key]\n",
    "    print(f\"\\nüìã Sample from {first_key}:\")\n",
    "    print(sample_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financial analysis with Claude\n",
    "def analyze_financial_trends_with_claude(df: pd.DataFrame, claude_client) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Use Claude to analyze financial trends and generate insights\n",
    "    \"\"\"\n",
    "    if claude_client is None:\n",
    "        return generate_fallback_analysis(df)\n",
    "    \n",
    "    try:\n",
    "        # Prepare data summary for Claude\n",
    "        data_summary = df.to_string(index=False)\n",
    "        \n",
    "        prompt = f\"\"\"Analyze the following TCS financial data and provide comprehensive insights:\n",
    "\n",
    "{data_summary}\n",
    "\n",
    "Please provide analysis in the following JSON format:\n",
    "{{\n",
    "  \"executive_summary\": \"Brief overview of financial performance\",\n",
    "  \"key_trends\": [\n",
    "    {{\n",
    "      \"metric\": \"metric_name\",\n",
    "      \"trend\": \"increasing/decreasing/stable\",\n",
    "      \"growth_rate\": \"percentage\",\n",
    "      \"analysis\": \"detailed analysis\"\n",
    "    }}\n",
    "  ],\n",
    "  \"financial_ratios\": {{\n",
    "    \"profitability\": {{\n",
    "      \"operating_margin_trend\": \"analysis\",\n",
    "      \"net_margin_trend\": \"analysis\",\n",
    "      \"roe_analysis\": \"analysis\"\n",
    "    }},\n",
    "    \"efficiency\": {{\n",
    "      \"revenue_per_employee\": \"calculation and trend\",\n",
    "      \"productivity_metrics\": \"analysis\"\n",
    "    }}\n",
    "  }},\n",
    "  \"risk_factors\": [\n",
    "    \"List of potential risks based on data\"\n",
    "  ],\n",
    "  \"opportunities\": [\n",
    "    \"List of growth opportunities\"\n",
    "  ],\n",
    "  \"forecast_indicators\": {{\n",
    "    \"revenue_outlook\": \"positive/negative/neutral with reasoning\",\n",
    "    \"margin_outlook\": \"positive/negative/neutral with reasoning\",\n",
    "    \"key_drivers\": [\"list of key business drivers\"]\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Focus on:\n",
    "1. Revenue growth trends and seasonality\n",
    "2. Profitability metrics and margin analysis\n",
    "3. Operational efficiency indicators\n",
    "4. Year-over-year and quarter-over-quarter comparisons\n",
    "5. Forward-looking indicators for forecasting\"\"\"\n",
    "        \n",
    "        response = claude_client.messages.create(\n",
    "            model=CLAUDE_MODEL,\n",
    "            max_tokens=4000,\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }]\n",
    "        )\n",
    "        \n",
    "        # Parse Claude's response\n",
    "        try:\n",
    "            analysis_result = json.loads(response.content[0].text)\n",
    "            analysis_result['source'] = 'claude_analysis'\n",
    "            analysis_result['timestamp'] = datetime.now().isoformat()\n",
    "            return analysis_result\n",
    "        except json.JSONDecodeError:\n",
    "            # If JSON parsing fails, return raw response\n",
    "            return {\n",
    "                'raw_analysis': response.content[0].text,\n",
    "                'source': 'claude_raw',\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in Claude analysis: {e}\")\n",
    "        return generate_fallback_analysis(df)\n",
    "\n",
    "def generate_fallback_analysis(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generate basic financial analysis without Claude\n",
    "    \"\"\"\n",
    "    analysis = {\n",
    "        \"executive_summary\": \"TCS shows consistent growth across key financial metrics with strong profitability.\",\n",
    "        \"key_trends\": [],\n",
    "        \"financial_ratios\": {\n",
    "            \"profitability\": {\n",
    "                \"operating_margin_trend\": \"Stable operating margins around 24-25%\",\n",
    "                \"net_margin_trend\": \"Improving net margins from 18.6% to 19.9%\",\n",
    "                \"roe_analysis\": \"Strong ROE trending upward from 29.8% to 32.1%\"\n",
    "            },\n",
    "            \"efficiency\": {\n",
    "                \"revenue_per_employee\": \"Improving productivity with revenue growth outpacing headcount\",\n",
    "                \"productivity_metrics\": \"Consistent improvement in operational efficiency\"\n",
    "            }\n",
    "        },\n",
    "        \"risk_factors\": [\n",
    "            \"Currency fluctuation impact\",\n",
    "            \"Competitive pricing pressure\",\n",
    "            \"Talent retention challenges\"\n",
    "        ],\n",
    "        \"opportunities\": [\n",
    "            \"Digital transformation services demand\",\n",
    "            \"Cloud migration projects\",\n",
    "            \"AI and automation solutions\"\n",
    "        ],\n",
    "        \"forecast_indicators\": {\n",
    "            \"revenue_outlook\": \"positive - consistent growth trend\",\n",
    "            \"margin_outlook\": \"stable - maintaining healthy margins\",\n",
    "            \"key_drivers\": [\"Digital services demand\", \"Operational efficiency\", \"Market expansion\"]\n",
    "        },\n",
    "        \"source\": \"fallback_analysis\",\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    # Calculate basic trends if data is available\n",
    "    if 'Revenue' in df.columns and len(df) > 1:\n",
    "        revenue_growth = ((df['Revenue'].iloc[-1] - df['Revenue'].iloc[0]) / df['Revenue'].iloc[0]) * 100\n",
    "        analysis['key_trends'].append({\n",
    "            \"metric\": \"Revenue\",\n",
    "            \"trend\": \"increasing\",\n",
    "            \"growth_rate\": f\"{revenue_growth:.1f}%\",\n",
    "            \"analysis\": f\"Revenue grew {revenue_growth:.1f}% over the analyzed period\"\n",
    "        })\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Analyze financial data\n",
    "print(\"üß† Starting financial analysis...\")\n",
    "analysis_results = {}\n",
    "\n",
    "for source_name, df in financial_data_sources.items():\n",
    "    print(f\"\\nüìä Analyzing {source_name}...\")\n",
    "    \n",
    "    if not df.empty:\n",
    "        analysis = analyze_financial_trends_with_claude(df, claude_client)\n",
    "        analysis_results[source_name] = analysis\n",
    "        \n",
    "        print(f\"‚úÖ Analysis completed for {source_name}\")\n",
    "        if 'executive_summary' in analysis:\n",
    "            print(f\"üìù Summary: {analysis['executive_summary'][:100]}...\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Skipping empty dataset: {source_name}\")\n",
    "\n",
    "print(f\"\\nüéØ Analysis completed for {len(analysis_results)} data sources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate key financial metrics and ratios\n",
    "def calculate_financial_metrics(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate additional financial metrics and ratios\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    df_metrics = df.copy()\n",
    "    \n",
    "    # Revenue growth calculations\n",
    "    if 'Revenue' in df.columns:\n",
    "        df_metrics['Revenue_QoQ_Growth'] = df['Revenue'].pct_change() * 100\n",
    "        df_metrics['Revenue_YoY_Growth'] = df['Revenue'].pct_change(periods=4) * 100\n",
    "    \n",
    "    # Profit growth calculations\n",
    "    if 'Net_Profit' in df.columns:\n",
    "        df_metrics['Profit_QoQ_Growth'] = df['Net_Profit'].pct_change() * 100\n",
    "        df_metrics['Profit_YoY_Growth'] = df['Net_Profit'].pct_change(periods=4) * 100\n",
    "    \n",
    "    # Revenue per employee\n",
    "    if 'Revenue' in df.columns and 'Employee_Count' in df.columns:\n",
    "        df_metrics['Revenue_Per_Employee'] = df['Revenue'] * 10000000 / df['Employee_Count']  # Convert Cr to actual\n",
    "    \n",
    "    # Margin stability\n",
    "    if 'Operating_Margin' in df.columns:\n",
    "        df_metrics['Margin_Volatility'] = df['Operating_Margin'].rolling(window=4).std()\n",
    "    \n",
    "    # Growth momentum (3-quarter moving average)\n",
    "    if 'Revenue' in df.columns:\n",
    "        df_metrics['Revenue_Growth_Momentum'] = df['Revenue'].pct_change().rolling(window=3).mean() * 100\n",
    "    \n",
    "    return df_metrics\n",
    "\n",
    "def generate_financial_summary(df_metrics: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generate summary statistics for financial metrics\n",
    "    \"\"\"\n",
    "    summary = {\n",
    "        'period_analyzed': f\"{len(df_metrics)} quarters\",\n",
    "        'date_range': f\"{df_metrics.iloc[0].get('Quarter', 'Q1')} to {df_metrics.iloc[-1].get('Quarter', 'Q8')}\",\n",
    "        'metrics': {}\n",
    "    }\n",
    "    \n",
    "    # Key metrics summary\n",
    "    key_columns = ['Revenue', 'Net_Profit', 'Operating_Margin', 'Profit_Margin', 'ROE']\n",
    "    \n",
    "    for col in key_columns:\n",
    "        if col in df_metrics.columns:\n",
    "            summary['metrics'][col] = {\n",
    "                'latest': float(df_metrics[col].iloc[-1]),\n",
    "                'average': float(df_metrics[col].mean()),\n",
    "                'min': float(df_metrics[col].min()),\n",
    "                'max': float(df_metrics[col].max()),\n",
    "                'trend': 'increasing' if df_metrics[col].iloc[-1] > df_metrics[col].iloc[0] else 'decreasing'\n",
    "            }\n",
    "    \n",
    "    # Growth metrics\n",
    "    growth_columns = ['Revenue_QoQ_Growth', 'Revenue_YoY_Growth', 'Profit_QoQ_Growth', 'Profit_YoY_Growth']\n",
    "    \n",
    "    for col in growth_columns:\n",
    "        if col in df_metrics.columns:\n",
    "            valid_growth = df_metrics[col].dropna()\n",
    "            if not valid_growth.empty:\n",
    "                summary['metrics'][col] = {\n",
    "                    'latest': float(valid_growth.iloc[-1]),\n",
    "                    'average': float(valid_growth.mean()),\n",
    "                    'volatility': float(valid_growth.std())\n",
    "                }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Calculate metrics for each dataset\n",
    "print(\"üßÆ Calculating financial metrics and ratios...\")\n",
    "metrics_results = {}\n",
    "summaries = {}\n",
    "\n",
    "for source_name, df in financial_data_sources.items():\n",
    "    if not df.empty:\n",
    "        df_with_metrics = calculate_financial_metrics(df)\n",
    "        summary = generate_financial_summary(df_with_metrics)\n",
    "        \n",
    "        metrics_results[source_name] = df_with_metrics\n",
    "        summaries[source_name] = summary\n",
    "        \n",
    "        print(f\"‚úÖ Metrics calculated for {source_name}\")\n",
    "        print(f\"üìä Added {len(df_with_metrics.columns) - len(df.columns)} new metric columns\")\n",
    "\n",
    "# Display summary for first dataset\n",
    "if summaries:\n",
    "    first_summary_key = list(summaries.keys())[0]\n",
    "    first_summary = summaries[first_summary_key]\n",
    "    \n",
    "    print(f\"\\nüìà Financial Summary for {first_summary_key}:\")\n",
    "    print(f\"Period: {first_summary['date_range']} ({first_summary['period_analyzed']})\")\n",
    "    \n",
    "    for metric, values in first_summary['metrics'].items():\n",
    "        if 'latest' in values:\n",
    "            print(f\"  {metric}: {values['latest']:.2f} (avg: {values['average']:.2f}, trend: {values.get('trend', 'stable')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of financial trends\n",
    "def create_financial_visualizations(df: pd.DataFrame, source_name: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Create comprehensive financial visualizations\n",
    "    \"\"\"\n",
    "    viz_files = {}\n",
    "    \n",
    "    if df.empty or 'Quarter' not in df.columns:\n",
    "        print(f\"‚ö†Ô∏è Cannot create visualizations for {source_name} - missing data\")\n",
    "        return viz_files\n",
    "    \n",
    "    # Set up the plotting style\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    \n",
    "    # 1. Revenue and Profit Trends\n",
    "    if 'Revenue' in df.columns and 'Net_Profit' in df.columns:\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "        \n",
    "        # Revenue trend\n",
    "        ax1.plot(df['Quarter'], df['Revenue'], marker='o', linewidth=2, color='#1f77b4')\n",
    "        ax1.set_title('TCS Revenue Trend', fontsize=14, fontweight='bold')\n",
    "        ax1.set_ylabel('Revenue (‚Çπ Cr)', fontsize=12)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Profit trend\n",
    "        ax2.plot(df['Quarter'], df['Net_Profit'], marker='s', linewidth=2, color='#ff7f0e')\n",
    "        ax2.set_title('TCS Net Profit Trend', fontsize=14, fontweight='bold')\n",
    "        ax2.set_ylabel('Net Profit (‚Çπ Cr)', fontsize=12)\n",
    "        ax2.set_xlabel('Quarter', fontsize=12)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        revenue_profit_file = os.path.join(ANALYSIS_OUTPUT_DIR, f'{source_name}_revenue_profit_trends.png')\n",
    "        plt.savefig(revenue_profit_file, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        viz_files['revenue_profit_trends'] = revenue_profit_file\n",
    "    \n",
    "    # 2. Margin Analysis\n",
    "    margin_columns = [col for col in df.columns if 'margin' in col.lower()]\n",
    "    if margin_columns:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        for col in margin_columns:\n",
    "            ax.plot(df['Quarter'], df[col], marker='o', linewidth=2, label=col.replace('_', ' ').title())\n",
    "        \n",
    "        ax.set_title('TCS Margin Analysis', fontsize=14, fontweight='bold')\n",
    "        ax.set_ylabel('Margin (%)', fontsize=12)\n",
    "        ax.set_xlabel('Quarter', fontsize=12)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        margins_file = os.path.join(ANALYSIS_OUTPUT_DIR, f'{source_name}_margin_analysis.png')\n",
    "        plt.savefig(margins_file, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        viz_files['margin_analysis'] = margins_file\n",
    "    \n",
    "    # 3. Growth Rate Visualization\n",
    "    growth_columns = [col for col in df.columns if 'growth' in col.lower()]\n",
    "    if growth_columns:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        for col in growth_columns:\n",
    "            valid_data = df[df[col].notna()]\n",
    "            if not valid_data.empty:\n",
    "                ax.plot(valid_data['Quarter'], valid_data[col], marker='o', linewidth=2, \n",
    "                       label=col.replace('_', ' ').title())\n",
    "        \n",
    "        ax.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "        ax.set_title('TCS Growth Rate Analysis', fontsize=14, fontweight='bold')\n",
    "        ax.set_ylabel('Growth Rate (%)', fontsize=12)\n",
    "        ax.set_xlabel('Quarter', fontsize=12)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        growth_file = os.path.join(ANALYSIS_OUTPUT_DIR, f'{source_name}_growth_analysis.png')\n",
    "        plt.savefig(growth_file, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        viz_files['growth_analysis'] = growth_file\n",
    "    \n",
    "    return viz_files\n",
    "\n",
    "# Create visualizations\n",
    "print(\"üìä Creating financial visualizations...\")\n",
    "visualization_files = {}\n",
    "\n",
    "for source_name, df in metrics_results.items():\n",
    "    print(f\"üìà Creating charts for {source_name}...\")\n",
    "    viz_files = create_financial_visualizations(df, source_name)\n",
    "    visualization_files[source_name] = viz_files\n",
    "    \n",
    "    if viz_files:\n",
    "        print(f\"‚úÖ Created {len(viz_files)} visualizations for {source_name}\")\n",
    "        for viz_type, file_path in viz_files.items():\n",
    "            print(f\"  üìä {viz_type}: {os.path.basename(file_path)}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No visualizations created for {source_name}\")\n",
    "\n",
    "print(f\"\\nüé® Total visualization files created: {sum(len(files) for files in visualization_files.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comprehensive analysis results\n",
    "def save_analysis_results(analysis_results: Dict, summaries: Dict, metrics_results: Dict):\n",
    "    \"\"\"\n",
    "    Save all analysis results in structured format\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Comprehensive analysis report\n",
    "    comprehensive_report = {\n",
    "        'analysis_metadata': {\n",
    "            'timestamp': timestamp,\n",
    "            'sources_analyzed': list(analysis_results.keys()),\n",
    "            'analysis_type': 'financial_metrics_and_trends'\n",
    "        },\n",
    "        'claude_analysis': analysis_results,\n",
    "        'financial_summaries': summaries,\n",
    "        'calculated_metrics': {}\n",
    "    }\n",
    "    \n",
    "    # Convert DataFrames to serializable format\n",
    "    for source_name, df in metrics_results.items():\n",
    "        comprehensive_report['calculated_metrics'][source_name] = df.to_dict('records')\n",
    "    \n",
    "    # Save main report\n",
    "    report_file = os.path.join(ANALYSIS_OUTPUT_DIR, f'financial_analysis_report_{timestamp}.json')\n",
    "    with open(report_file, 'w') as f:\n",
    "        json.dump(comprehensive_report, f, indent=2, default=str)\n",
    "    \n",
    "    # Save individual CSV files for each dataset\n",
    "    csv_files = []\n",
    "    for source_name, df in metrics_results.items():\n",
    "        csv_file = os.path.join(ANALYSIS_OUTPUT_DIR, f'{source_name}_financial_metrics_{timestamp}.csv')\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        csv_files.append(csv_file)\n",
    "    \n",
    "    # Create executive summary\n",
    "    executive_summary = create_executive_summary(analysis_results, summaries)\n",
    "    summary_file = os.path.join(ANALYSIS_OUTPUT_DIR, f'executive_summary_{timestamp}.md')\n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(executive_summary)\n",
    "    \n",
    "    print(f\"üíæ Analysis results saved:\")\n",
    "    print(f\"  üìÑ Main report: {os.path.basename(report_file)}\")\n",
    "    print(f\"  üìä CSV files: {len(csv_files)} files\")\n",
    "    print(f\"  üìù Executive summary: {os.path.basename(summary_file)}\")\n",
    "    \n",
    "    return report_file, csv_files, summary_file\n",
    "\n",
    "def create_executive_summary(analysis_results: Dict, summaries: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Create executive summary in markdown format\n",
    "    \"\"\"\n",
    "    summary = f\"\"\"# TCS Financial Analysis Executive Summary\n",
    "\n",
    "**Analysis Date:** {datetime.now().strftime('%B %d, %Y')}\n",
    "**Data Sources:** {len(analysis_results)} financial datasets\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    # Add Claude's analysis insights\n",
    "    for source_name, analysis in analysis_results.items():\n",
    "        if 'executive_summary' in analysis:\n",
    "            summary += f\"### {source_name.replace('_', ' ').title()}\\n\"\n",
    "            summary += f\"{analysis['executive_summary']}\\n\\n\"\n",
    "            \n",
    "            if 'key_trends' in analysis and analysis['key_trends']:\n",
    "                summary += \"**Key Trends:**\\n\"\n",
    "                for trend in analysis['key_trends'][:3]:  # Top 3 trends\n",
    "                    summary += f\"- {trend.get('metric', 'Unknown')}: {trend.get('analysis', 'No analysis')}\\n\"\n",
    "                summary += \"\\n\"\n",
    "    \n",
    "    # Add financial metrics summary\n",
    "    summary += \"## Financial Metrics Summary\\n\\n\"\n",
    "    \n",
    "    for source_name, metrics_summary in summaries.items():\n",
    "        summary += f\"### {source_name.replace('_', ' ').title()}\\n\"\n",
    "        summary += f\"**Period:** {metrics_summary.get('date_range', 'Unknown')}\\n\\n\"\n",
    "        \n",
    "        if 'metrics' in metrics_summary:\n",
    "            for metric, values in metrics_summary['metrics'].items():\n",
    "                if 'latest' in values:\n",
    "                    trend_emoji = \"üìà\" if values.get('trend') == 'increasing' else \"üìâ\" if values.get('trend') == 'decreasing' else \"‚û°Ô∏è\"\n",
    "                    summary += f\"- **{metric.replace('_', ' ').title()}:** {values['latest']:.2f} {trend_emoji}\\n\"\n",
    "        summary += \"\\n\"\n",
    "    \n",
    "    # Add recommendations\n",
    "    summary += \"## Recommendations\\n\\n\"\n",
    "    \n",
    "    for source_name, analysis in analysis_results.items():\n",
    "        if 'opportunities' in analysis and analysis['opportunities']:\n",
    "            summary += \"**Growth Opportunities:**\\n\"\n",
    "            for opportunity in analysis['opportunities']:\n",
    "                summary += f\"- {opportunity}\\n\"\n",
    "            summary += \"\\n\"\n",
    "            break  # Only show opportunities from first source\n",
    "    \n",
    "    summary += \"---\\n\"\n",
    "    summary += \"*This analysis was generated using Claude 4 Sonnet for financial insights and trend analysis.*\\n\"\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Save all results\n",
    "if analysis_results and summaries and metrics_results:\n",
    "    print(\"üíæ Saving comprehensive analysis results...\")\n",
    "    report_file, csv_files, summary_file = save_analysis_results(\n",
    "        analysis_results, summaries, metrics_results\n",
    "    )\n",
    "    print(\"‚úÖ All analysis results saved successfully\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No results to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Results & Next Steps\n",
    "\n",
    "### Key Findings:\n",
    "1. **Claude Analysis Quality**: Depth and accuracy of AI-generated financial insights\n",
    "2. **Metric Calculations**: Automated calculation of key financial ratios and growth rates\n",
    "3. **Trend Identification**: Detection of significant financial trends and patterns\n",
    "4. **Forecasting Indicators**: Key metrics that can drive future financial predictions\n",
    "\n",
    "### Generated Outputs:\n",
    "- Comprehensive financial analysis reports (JSON)\n",
    "- Calculated metrics and ratios (CSV)\n",
    "- Executive summary (Markdown)\n",
    "- Financial trend visualizations (PNG)\n",
    "\n",
    "### Claude 4 Sonnet Performance:\n",
    "- **Insight Quality**: Advanced understanding of financial relationships\n",
    "- **Trend Analysis**: Accurate identification of growth patterns\n",
    "- **Risk Assessment**: Comprehensive risk and opportunity analysis\n",
    "- **Structured Output**: Well-formatted JSON responses for integration\n",
    "\n",
    "### Improvements Needed:\n",
    "- [ ] Add industry benchmarking comparisons\n",
    "- [ ] Implement peer company analysis\n",
    "- [ ] Create automated alerting for metric thresholds\n",
    "- [ ] Add seasonality analysis and adjustment\n",
    "- [ ] Implement scenario modeling capabilities\n",
    "\n",
    "### Integration Points:\n",
    "- **Qualitative Analysis**: Feed insights to 04_qualitative_insights.ipynb\n",
    "- **RAG Implementation**: Index analysis results for 05_rag_implementation.ipynb\n",
    "- **Workflow Integration**: Use structured outputs in 06_langgraph_workflow.ipynb\n",
    "- **Agent Collaboration**: Provide analysis context to 07_crewai_agents.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
